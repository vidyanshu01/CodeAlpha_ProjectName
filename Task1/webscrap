import requests
from bs4 import BeautifulSoup
import csv

# Base URL
url = 'http://quotes.toscrape.com/page/{}/'

# Empty list to hold the quotes
all_quotes = []

for page in range(1, 6):
    response = requests.get(url.format(page))
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find all quote blocks
    quotes = soup.find_all('div', class_='quote')

    for quote in quotes:
        text = quote.find('span', class_='text').text.strip()
        author = quote.find('small', class_='author').text.strip()
        tags = [tag.text for tag in quote.find_all('a', class_='tag')]

        all_quotes.append({
            'Quote': text,
            'Author': author,
            'Tags': ', '.join(tags)
        })

# Save to CSV
with open('quotes.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=['Quote', 'Author', 'Tags'])
    writer.writeheader()
    writer.writerows(all_quotes)

